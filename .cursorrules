# SaaS Analytics & Data Quality Project - Cursor Rules

## ðŸŽ¯ Project Mission
Build a portfolio-worthy SaaS analytics platform that showcases **depth over breadth** - demonstrating mastery of data modeling, data quality, and business metrics with production-grade practices.

## ðŸ“‹ Core Principles

### 1. Quality Over Speed
- Every model must be tested before moving to the next
- Data quality is non-negotiable
- If you can't test it, refactor it until you can

### 2. Business First, Technical Second
- Every metric must have a clear business purpose
- Code comments explain business context, not syntax
- Metric definitions should be understandable by non-technical stakeholders

### 3. Production Mindset
- Write like this will run in production tomorrow
- Every dependency must be in requirements.txt
- Error messages should be actionable
- Documentation is part of the deliverable, not an afterthought

---

## ðŸ—‚ï¸ dbt Guidelines

### Model Organization (Strict)

```
models/
â”œâ”€â”€ staging/        # stg_* - 1:1 with source, cleaning only
â”œâ”€â”€ intermediate/   # int_* - business logic, joins
â””â”€â”€ marts/         # fct_*/dim_* - final analytics tables
    â”œâ”€â”€ core/      # Dimensional models
    â””â”€â”€ saas_metrics/  # Business metrics
```

**Rules:**
- **Staging**: No joins, no business logic, only cleaning
- **Intermediate**: Can join, can have business logic, not for BI consumption
- **Marts**: Optimized for dashboards, comprehensive tests, well-documented

### SQL Style (Non-Negotiable)

```sql
-- GOOD: Clean, readable, tested
with customers as (
    select
        customer_id,
        email,
        company_name,
        signup_date,
        account_status
    from {{ ref('stg_customers') }}
),

subscriptions as (
    select
        subscription_id,
        customer_id,
        {{ calculate_mrr('amount', 'billing_cycle') }} as mrr_amount,
        status
    from {{ ref('stg_subscriptions') }}
    where status = 'active'
)

select
    c.customer_id,
    c.company_name,
    sum(s.mrr_amount) as total_mrr,
    count(s.subscription_id) as subscription_count
from customers c
left join subscriptions s
    on c.customer_id = s.customer_id
group by 1, 2
```

**Style Rules:**
- Lowercase for keywords: `select`, `from`, `where`
- One column per line in SELECT
- Trailing commas (easier to add/remove lines)
- CTEs over subqueries (readability)
- Meaningful CTE names (what data does it contain?)
- Always use `{{ ref() }}` or `{{ source() }}` - never hardcode table names

### Testing Requirements

**Every mart model MUST have:**
```yaml
# models/marts/core/_core_schema.yml
models:
  - name: dim_customers
    description: "Customer dimension with current attributes and calculated fields"
    columns:
      - name: customer_id
        description: "Unique customer identifier"
        tests:
          - unique
          - not_null
      
      - name: email
        description: "Customer email address"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_match_regex:
              regex: "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
      
      - name: total_lifetime_value
        description: "Sum of all revenue from this customer"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: 0
              max_value: 1000000
```

**Test Coverage Goals:**
- Staging: 100% primary keys tested (unique + not_null)
- Intermediate: 80%+ columns with at least one test
- Marts: 95%+ comprehensive testing
- Every foreign key: relationships test
- Every monetary value: range check (>= 0)
- Every status field: accepted_values test

### Macros for Reusability

**Create macros for repeated logic:**

```sql
-- macros/calculate_mrr.sql
{% macro calculate_mrr(amount, billing_cycle) %}
    case 
        when {{ billing_cycle }} = 'annual' then {{ amount }} / 12.0
        when {{ billing_cycle }} = 'monthly' then {{ amount }}
        when {{ billing_cycle }} = 'quarterly' then {{ amount }} / 3.0
        else 0
    end
{% endmacro %}
```

**When to create a macro:**
- Logic used in 3+ models
- Complex calculations (MRR, churn rate)
- Business rules that might change
- Date manipulations used repeatedly

### Documentation Standards

**Every model needs schema.yml with:**
1. Clear description (what is this model?)
2. Why it exists (what business question does it answer?)
3. Column descriptions (especially calculated fields)
4. Tests

```yaml
models:
  - name: mrr_analysis
    description: |
      Monthly recurring revenue analysis with MRR movement breakdown.
      
      Business Context:
      This model powers the executive MRR dashboard and is used to track
      revenue growth, expansion, and churn.
      
      Grain: One row per month
      
      Update Frequency: Daily (incremental)
    
    columns:
      - name: date_month
        description: "First day of the month (YYYY-MM-01)"
        tests:
          - unique
          - not_null
      
      - name: new_mrr
        description: "MRR from customers who started subscriptions this month"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: 0
```

---

## ðŸ Python Guidelines

### Data Generation Script

**Structure:**
```python
# data_generation/generate_saas_data.py

"""
Generate synthetic SaaS subscription data.

This script creates realistic subscription lifecycle data including:
- Customers with various segments and industries
- Subscriptions with upgrades, downgrades, and churn
- Usage events correlated with retention
- Payment transactions with realistic failure rates

Output: CSV files in /data/raw/ ready to load into DuckDB
"""

import pandas as pd
import numpy as np
from faker import Faker
from datetime import datetime, timedelta
from typing import Dict, List
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants
NUM_CUSTOMERS = 10000
NUM_SUBSCRIPTIONS = 50000
START_DATE = datetime(2022, 1, 1)
END_DATE = datetime(2024, 12, 31)

def generate_customers(num_customers: int) -> pd.DataFrame:
    """
    Generate customer records with realistic attributes.
    
    Args:
        num_customers: Number of customer records to generate
        
    Returns:
        DataFrame with customer data
        
    Business Logic:
    - 60% SMB, 30% Mid-Market, 10% Enterprise
    - Signup dates distributed evenly with seasonal variation
    - 5% churn rate (customers with end_date set)
    """
    logger.info(f"Generating {num_customers} customer records...")
    
    # Implementation here
    
    return customers_df
```

**Code Quality Requirements:**
- Type hints for all functions
- Docstrings with Args, Returns, and Business Logic
- Logging for progress tracking
- Constants at top of file (no magic numbers)
- Seed random generators for reproducibility

### Quality Monitoring Scripts

**Structure:**
```python
# quality_monitoring/anomaly_detection.py

"""
Detect anomalies in key SaaS metrics.

This script identifies when metrics deviate significantly from expected patterns:
- MRR drops exceeding 15% week-over-week
- Churn spikes above 2x rolling average
- Missing data (no new subscriptions in 24h)

Alerts are logged and can be sent to Slack/email in production.
"""

import duckdb
import pandas as pd
from scipy import stats
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

def detect_mrr_anomalies(db_path: str, threshold_z: float = 2.5) -> pd.DataFrame:
    """
    Detect MRR anomalies using Z-score method.
    
    Args:
        db_path: Path to DuckDB database
        threshold_z: Z-score threshold for flagging anomalies (default: 2.5)
        
    Returns:
        DataFrame with flagged anomalies
        
    Algorithm:
    1. Calculate daily MRR for last 90 days
    2. Compute rolling mean and std dev
    3. Flag days where z-score > threshold
    """
    conn = duckdb.connect(db_path)
    
    # Query MRR data
    query = """
        SELECT 
            date_trunc('day', date) as day,
            SUM(mrr_amount) as total_mrr
        FROM fct_monthly_recurring_revenue
        WHERE date >= CURRENT_DATE - INTERVAL 90 DAY
        GROUP BY 1
        ORDER BY 1
    """
    
    df = conn.execute(query).df()
    
    # Calculate z-scores
    df['rolling_mean'] = df['total_mrr'].rolling(window=7).mean()
    df['rolling_std'] = df['total_mrr'].rolling(window=7).std()
    df['z_score'] = (df['total_mrr'] - df['rolling_mean']) / df['rolling_std']
    
    # Flag anomalies
    anomalies = df[abs(df['z_score']) > threshold_z]
    
    if len(anomalies) > 0:
        logger.warning(f"Found {len(anomalies)} MRR anomalies")
        for _, row in anomalies.iterrows():
            logger.warning(f"  {row['day']}: MRR=${row['total_mrr']:,.0f} (z={row['z_score']:.2f})")
    else:
        logger.info("No MRR anomalies detected")
    
    conn.close()
    return anomalies
```

**Requirements:**
- Handle missing data gracefully
- Log all findings (info for normal, warning for anomalies)
- Return structured results (DataFrames, not prints)
- Include thresholds as parameters (not hardcoded)

---

## ðŸ“Š SaaS Metrics Calculation Guidelines

### MRR (Monthly Recurring Revenue)

```sql
-- CORRECT: Handle all billing cycles
{{ calculate_mrr('subscription_amount', 'billing_cycle') }} as mrr_amount

-- WRONG: Assumes monthly only
subscription_amount as mrr_amount
```

### Churn Rate Calculation

```sql
-- CORRECT: Period-specific churn
with month_start as (
    select count(distinct customer_id) as starting_customers
    from fct_subscriptions
    where date = '2024-01-01'
    and status in ('active', 'trial')
),
month_churned as (
    select count(distinct customer_id) as churned_customers
    from fct_subscriptions
    where churned_date between '2024-01-01' and '2024-01-31'
)
select 
    churned_customers::float / starting_customers as churn_rate
from month_start, month_churned

-- WRONG: Mixing time periods
select 
    count(case when status = 'churned' end)::float / count(*) as churn_rate
from fct_subscriptions
-- This mixes all-time churned with current total = incorrect
```

### Cohort Retention

```sql
-- Structure for cohort analysis
with cohorts as (
    select
        customer_id,
        date_trunc('month', signup_date) as cohort_month
    from dim_customers
),
customer_months as (
    select
        c.cohort_month,
        s.customer_id,
        date_trunc('month', s.date) as active_month,
        datediff('month', c.cohort_month, s.date) as months_since_signup
    from cohorts c
    join fct_subscriptions s on c.customer_id = s.customer_id
    where s.status = 'active'
)
select
    cohort_month,
    months_since_signup,
    count(distinct customer_id) as active_customers
from customer_months
group by 1, 2
order by 1, 2
```

---

## ðŸ“ File Organization & Naming

### File Naming Conventions

**dbt models:**
- `stg_[source_table].sql` - e.g., `stg_customers.sql`
- `int_[description].sql` - e.g., `int_subscription_periods.sql`
- `fct_[grain].sql` - e.g., `fct_subscriptions.sql`
- `dim_[entity].sql` - e.g., `dim_customers.sql`

**Python files:**
- `snake_case.py` - e.g., `generate_saas_data.py`
- Descriptive names - `anomaly_detection.py` not `check.py`

**YAML files:**
- `_[folder_name]_schema.yml` - e.g., `_staging_schema.yml`
- Keeps schema files grouped with models

### Directory Structure Rules

1. **Related files together** - all staging models in /staging/
2. **One schema.yml per directory** - easier to find
3. **Separate tests/** for complex custom tests
4. **Macros by purpose** - `calculations/`, `utilities/`

---

## âœ… Git & Version Control

### Commit Message Format

```
âœ… GOOD:
"Add churn_analysis model with customer and revenue churn calculations"
"Fix: Handle null billing_cycle in MRR calculation macro"
"Test: Add range validation for lifetime_value in dim_customers"
"Docs: Document MRR waterfall methodology in metrics catalog"

âŒ BAD:
"updates"
"fix bug"
"wip"
"changed stuff"
```

**Structure:**
```
[Type]: [Clear description of what changed and why]

Types: Add, Fix, Test, Docs, Refactor, Perf
```

### Branch Naming

- `feature/cohort-retention-model` - new features
- `fix/mrr-calculation-annual` - bug fixes
- `test/add-churn-validation` - adding tests
- `docs/metrics-catalog` - documentation

### Pre-Commit Checklist

Before every commit:
- [ ] `dbt test` passes (all tests green)
- [ ] `dbt run` completes without errors
- [ ] No `select *` in final models (be explicit)
- [ ] All new models have tests
- [ ] All new models have descriptions
- [ ] No hardcoded values (use macros/variables)
- [ ] Requirements.txt updated if new packages

---

## ðŸ§ª Testing Strategy

### Test Pyramid

**Base (Most tests here):**
- unique, not_null on all primary keys
- relationships on all foreign keys
- accepted_values on all status/category fields

**Middle:**
- dbt_expectations range checks on numeric fields
- Regex validation on formatted fields (email, phone)
- Row count checks (tables shouldn't be empty)

**Top (Fewer, but critical):**
- Custom business logic tests
- Metric validation (MRR calculations correct?)
- Cross-table consistency (totals match across models)

### Custom Test Example

```sql
-- tests/singular/mrr_matches_subscription_sum.sql
/*
Business Rule Test: Total MRR should equal sum of active subscription MRR

This catches:
- Missing subscriptions in MRR calculation
- Double-counting subscriptions
- Incorrect MRR formula
*/

with mrr_total as (
    select sum(mrr_amount) as total_mrr
    from {{ ref('fct_monthly_recurring_revenue') }}
    where date = current_date
),
subscription_sum as (
    select sum({{ calculate_mrr('amount', 'billing_cycle') }}) as total_mrr
    from {{ ref('stg_subscriptions') }}
    where status = 'active'
)

select
    abs(m.total_mrr - s.total_mrr) as difference
from mrr_total m
cross join subscription_sum s
where abs(m.total_mrr - s.total_mrr) > 0.01  -- Allow $0.01 rounding difference
```

---

## ðŸ“Š Dashboard & Documentation

### Evidence.dev Page Structure

```markdown
<!-- pages/mrr.md -->
# Monthly Recurring Revenue Analysis

## Key Metrics

```sql current_mrr
select 
    sum(mrr_amount) as current_mrr,
    sum(case when months_since_signup = 0 then mrr_amount end) as new_mrr,
    sum(case when mrr_change > 0 then mrr_change end) as expansion_mrr,
    sum(case when mrr_change < 0 then mrr_change end) as contraction_mrr,
    sum(case when status = 'churned' then previous_mrr end) as churned_mrr
from {{ ref('mrr_analysis') }}
where date = current_date
```

<BigValue 
  data={current_mrr}
  value='current_mrr'
  fmt='$#,##0'
/>

## MRR Trend

```sql mrr_trend
select
    date_month,
    total_mrr,
    new_mrr,
    expansion_mrr,
    contraction_mrr,
    churned_mrr
from {{ ref('mrr_analysis') }}
order by date_month
```

<LineChart
  data={mrr_trend}
  x='date_month'
  y='total_mrr'
/>
```

### Metrics Catalog Format

```markdown
# SaaS Metrics Catalog

## Monthly Recurring Revenue (MRR)

**Definition:** Sum of all normalized monthly subscription revenue from active customers.

**Calculation:**
- Monthly subscriptions: face value
- Annual subscriptions: divided by 12
- Quarterly subscriptions: divided by 3

**Business Context:**
MRR is the primary metric for tracking revenue growth in subscription businesses. It normalizes all billing cycles to a monthly value for consistent comparison.

**Usage:**
- Executive dashboard (top KPI)
- Investor reports
- Revenue forecasting

**Data Source:** `fct_monthly_recurring_revenue`

**Owner:** Analytics Team

**Update Frequency:** Daily

**Quality Checks:**
- MRR should equal sum of active subscription MRR
- MRR should only include paying customers (exclude trials)
- Annual MRR / 12 should equal monthly normalized value

---

## Customer Churn Rate

**Definition:** Percentage of customers who canceled their subscriptions in a given period.

**Calculation:**
```
Churn Rate = (Customers at Start of Period - Customers at End of Period) / Customers at Start of Period
```

**Why It Matters:**
High churn indicates product-market fit issues or customer satisfaction problems. SaaS companies target <5% monthly churn.

**Data Source:** `churn_analysis`

**Related Metrics:**
- Revenue Churn Rate (dollars lost vs customers lost)
- Net Revenue Retention (includes expansion)
```

---

## ðŸ’¡ When to Ask Cursor for Help

### Good Requests

**Specific and contextual:**
```
"I'm building the cohort_retention model. I need to:
1. Calculate months_since_signup for each customer
2. Group by cohort_month and months_since_signup
3. Calculate retention percentage vs cohort size
4. Handle customers who churn and return

Can you help me write the SQL with proper CTEs?"
```

**Code review:**
```
"Review this MRR calculation macro. Am I handling all edge cases?
- What if billing_cycle is null?
- Should I round to 2 decimals?
- Any performance concerns?"
```

**Testing strategy:**
```
"What tests should I add to dim_customers? I have unique/not_null on customer_id. What else is important for data quality?"
```

### Not-So-Good Requests

âŒ "Build the entire project"
âŒ "Make this better" (too vague)
âŒ "Fix the error" (without context/error message)
âŒ "What should I do next?" (check project_context.md phases)

### Effective Prompting Template

```
Context: [What model/script you're working on]
Goal: [What you're trying to achieve]
Current issue: [Specific problem or question]
Constraints: [Any requirements - performance, business rules, etc.]

Example:
Context: Building fct_monthly_recurring_revenue incremental model
Goal: Only process new/changed subscription records for performance
Current issue: Not sure how to write the incremental logic correctly
Constraints: Need to handle subscription updates and cancellations, not just new records
```

---

## ðŸš¨ Common Pitfalls to Avoid

### 1. Selecting Too Much Data

```sql
-- BAD: Bringing all columns through every CTE
with customers as (
    select * from {{ ref('stg_customers') }}  -- Carries 50 columns forward
),
...

-- GOOD: Only select what you need
with customers as (
    select
        customer_id,
        signup_date,
        account_status
    from {{ ref('stg_customers') }}
),
```

### 2. Not Handling Nulls

```sql
-- BAD: Division by zero errors
sum(revenue) / count(customers) as arpu

-- GOOD: Safe division
case 
    when count(customers) > 0 
    then sum(revenue)::float / count(customers)
    else 0 
end as arpu
```

### 3. Hardcoding Table Names

```sql
-- BAD: Breaks if source changes
from raw.customers

-- GOOD: Use dbt references
from {{ source('raw_saas', 'customers') }}
from {{ ref('stg_customers') }}
```

### 4. Missing Tests on Calculated Fields

```yaml
# BAD: No tests on calculated field
- name: lifetime_value
  description: "Customer lifetime value"

# GOOD: Validate calculation makes sense
- name: lifetime_value
  description: "Customer lifetime value"
  tests:
    - not_null
    - dbt_expectations.expect_column_values_to_be_between:
        min_value: 0
        max_value: 1000000
```

### 5. Unclear Metric Definitions

```sql
-- BAD: Ambiguous calculation
sum(amount) as revenue  -- Which revenue? Gross? Net? MRR? ARR?

-- GOOD: Explicit naming
sum(case when billing_cycle = 'monthly' then amount end) as monthly_subscription_revenue,
sum(amount / 12.0 when billing_cycle = 'annual' then amount / 12.0 end) as annualized_monthly_revenue
```

---

## ðŸŽ¯ Quality Gates

### Before Moving to Next Phase

**Phase 1 â†’ Phase 2:**
- [ ] Data generation script runs without errors
- [ ] All 6 source tables populated in DuckDB
- [ ] Can query tables successfully
- [ ] Data looks realistic (spot-check in SQL)

**Phase 2 â†’ Phase 3:**
- [ ] All staging models build successfully
- [ ] All intermediate models build successfully
- [ ] `dbt test` passes (100% of tests green)
- [ ] dbt docs generate works

**Phase 3 â†’ Phase 4:**
- [ ] All mart models build successfully
- [ ] Test coverage â‰¥95% on marts
- [ ] All SaaS metrics calculate correctly (spot-check numbers)
- [ ] dbt docs site looks complete

**Phase 4 â†’ Phase 5:**
- [ ] CI/CD pipeline passes
- [ ] Monitoring scripts run without errors
- [ ] dbt docs deployed to GitHub Pages
- [ ] No critical failing tests

**Phase 5 â†’ Done:**
- [ ] All 5 dashboards complete and screenshot
- [ ] README is polished and comprehensive
- [ ] All diagrams created
- [ ] Metrics catalog complete
- [ ] LinkedIn post drafted

---

## ðŸ”’ Security & Best Practices

### Environment Variables

```python
# .env (DO NOT COMMIT)
DB_PATH=./data/warehouse/saas_analytics.duckdb
RANDOM_SEED=42

# .env.example (COMMIT THIS)
DB_PATH=path/to/your/database.duckdb
RANDOM_SEED=42
```

### .gitignore Essentials

```
# Data files
data/raw/*.csv
data/warehouse/*.duckdb
*.parquet

# dbt artifacts
dbt_project/target/
dbt_project/logs/
dbt_project/dbt_packages/

# Python
__pycache__/
*.pyc
venv/
.env

# IDE
.vscode/
.cursor/
*.swp

# OS
.DS_Store
```

### Requirements.txt Management

```txt
# Core dependencies
dbt-core==1.7.0
dbt-duckdb==1.7.0
duckdb==0.9.2

# Data generation
faker==20.1.0
pandas==2.1.4
numpy==1.26.2

# Quality & monitoring
great-expectations==0.18.8
scipy==1.11.4

# Visualization (if using Evidence locally)
# evidence-dev - installed via npm

# Pin major versions, allow minor updates
# This ensures reproducibility while getting security patches
```

---

## ðŸ“š Documentation Checklist

Every completed phase should update:

**README.md:**
- [ ] Project overview
- [ ] What's been completed
- [ ] How to run what's done
- [ ] Next steps

**project_context.md:**
- [ ] Check off completed tasks
- [ ] Note any deviations from plan
- [ ] Update if approach changed

**dbt documentation:**
- [ ] All models have descriptions
- [ ] All calculated fields explained
- [ ] Tests documented in schema.yml

**Code comments:**
- [ ] Complex business logic explained
- [ ] Non-obvious decisions documented
- [ ] SQL CTEs have purpose comments

---

## ðŸŽ“ Success Criteria

This project is portfolio-ready when:

1. **Functionality**: All models build, all tests pass
2. **Quality**: 95%+ test coverage on marts layer
3. **Documentation**: README enables someone to set up in <20 minutes
4. **Business Value**: Clear metric definitions showing business understanding
5. **Technical Depth**: Advanced dbt features demonstrated
6. **Professionalism**: Clean code, proper git history, CI/CD working

**Remember:** This project showcases your **analytics engineering expertise**. Every file should demonstrate professional-level work. Quality matters more than quantity.

**You've got this! ðŸš€**